{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 5: GPU Training with Self-Play\n",
    "\n",
    "This notebook enables GPU-accelerated training on JupyterHub servers.\n",
    "\n",
    "## Features\n",
    "- Automatic GPU detection (CUDA/MPS)\n",
    "- Self-play training\n",
    "- Large map support (500x500+)\n",
    "- Continue training from Phase 3 models\n",
    "- Real-time monitoring\n",
    "\n",
    "## Prerequisites\n",
    "- JupyterHub with GPU access\n",
    "- CUDA 11.7+ (for NVIDIA GPUs)\n",
    "- Python 3.8+\n",
    "- All dependencies installed (see requirements.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), '..', 'src'))\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), '..', '..', 'phase3-implementation', 'src'))\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CUDA availability\n",
    "print(\"GPU Status:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✓ CUDA is available!\")\n",
    "    print(f\"  Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"  Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    \n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        print(f\"\\n  GPU {i}: {props.name}\")\n",
    "        print(f\"    Total Memory: {props.total_memory / 1e9:.2f} GB\")\n",
    "        print(f\"    Compute Capability: {props.major}.{props.minor}\")\n",
    "    \n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(f\"✓ Apple Metal (MPS) is available!\")\n",
    "    device = 'mps'\n",
    "else:\n",
    "    print(f\"⚠️  No GPU detected - using CPU (training will be VERY slow)\")\n",
    "    device = 'cpu'\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"Selected device: {device.upper()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration\n",
    "\n",
    "Adjust these parameters for your training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Configuration\n",
    "CONFIG = {\n",
    "    # Model\n",
    "    'phase3_model_path': None,  # Set to path of Phase 3 model to continue training\n",
    "    \n",
    "    # Environment\n",
    "    'map_name': 'australia_500x500',  # Map to train on\n",
    "    'num_bots': 10,                   # Number of opponent bots\n",
    "    'n_envs': 16,                     # Parallel environments (adjust based on GPU memory)\n",
    "    \n",
    "    # Training\n",
    "    'total_timesteps': 1_000_000,     # Total training steps\n",
    "    'learning_rate': 3e-4,            # Learning rate (use 1e-4 for fine-tuning)\n",
    "    'batch_size': 512,                # Batch size (512 for CUDA, 256 for MPS/CPU)\n",
    "    'n_steps': 2048,                  # Rollout steps (2048 for CUDA, 1024 for MPS/CPU)\n",
    "    \n",
    "    # Self-Play\n",
    "    'use_self_play': True,            # Enable self-play training\n",
    "    \n",
    "    # Output\n",
    "    'output_dir': f'../runs/run_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "}\n",
    "\n",
    "# Adjust batch size and n_steps based on device\n",
    "if device == 'mps' or device == 'cpu':\n",
    "    CONFIG['batch_size'] = 256\n",
    "    CONFIG['n_steps'] = 1024\n",
    "    CONFIG['n_envs'] = 8  # Fewer environments for non-CUDA\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Phase 3 Model (Optional)\n",
    "\n",
    "If you want to continue training from a Phase 3 model, set the path in the configuration above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "model = None\n",
    "\n",
    "if CONFIG['phase3_model_path']:\n",
    "    print(f\"Loading Phase 3 model from: {CONFIG['phase3_model_path']}\")\n",
    "    try:\n",
    "        model = PPO.load(CONFIG['phase3_model_path'], device=device)\n",
    "        print(\"✓ Model loaded successfully\")\n",
    "        \n",
    "        # Print model info\n",
    "        print(f\"  Policy: {type(model.policy).__name__}\")\n",
    "        print(f\"  Device: {model.device}\")\n",
    "        \n",
    "        # Use lower learning rate for fine-tuning\n",
    "        CONFIG['learning_rate'] = 1e-4\n",
    "        print(f\"  Adjusted learning rate to {CONFIG['learning_rate']} for fine-tuning\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to load model: {e}\")\n",
    "        print(\"  Starting from scratch instead\")\n",
    "        model = None\n",
    "else:\n",
    "    print(\"No Phase 3 model specified - starting from scratch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from environment_large import OpenFrontEnvLarge\n",
    "from self_play_env import SelfPlayEnv\n",
    "\n",
    "def make_env(rank):\n",
    "    \"\"\"Create a single environment\"\"\"\n",
    "    def _init():\n",
    "        if CONFIG['use_self_play']:\n",
    "            env = SelfPlayEnv(\n",
    "                num_bots=CONFIG['num_bots'],\n",
    "                map_name=CONFIG['map_name']\n",
    "            )\n",
    "        else:\n",
    "            env = OpenFrontEnvLarge(\n",
    "                num_bots=CONFIG['num_bots'],\n",
    "                map_name=CONFIG['map_name']\n",
    "            )\n",
    "        env = Monitor(env)\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "print(f\"Creating {CONFIG['n_envs']} parallel environments...\")\n",
    "env = SubprocVecEnv([make_env(i) for i in range(CONFIG['n_envs'])])\n",
    "print(\"✓ Environments created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create or Update Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import BattleRoyaleExtractor\n",
    "\n",
    "os.makedirs(CONFIG['output_dir'], exist_ok=True)\n",
    "os.makedirs(os.path.join(CONFIG['output_dir'], 'checkpoints'), exist_ok=True)\n",
    "os.makedirs(os.path.join(CONFIG['output_dir'], 'logs'), exist_ok=True)\n",
    "\n",
    "if model is None:\n",
    "    print(\"Creating new PPO model...\")\n",
    "    model = PPO(\n",
    "        policy=\"MultiInputPolicy\",\n",
    "        env=env,\n",
    "        learning_rate=CONFIG['learning_rate'],\n",
    "        n_steps=CONFIG['n_steps'],\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        n_epochs=10,\n",
    "        gamma=0.995,\n",
    "        gae_lambda=0.95,\n",
    "        clip_range=0.2,\n",
    "        ent_coef=0.03,\n",
    "        vf_coef=0.5,\n",
    "        max_grad_norm=0.5,\n",
    "        policy_kwargs={\n",
    "            'features_extractor_class': BattleRoyaleExtractor,\n",
    "            'features_extractor_kwargs': {'features_dim': 256}\n",
    "        },\n",
    "        verbose=1,\n",
    "        device=device,\n",
    "        tensorboard_log=os.path.join(CONFIG['output_dir'], 'logs')\n",
    "    )\n",
    "    print(\"✓ Model created\")\n",
    "else:\n",
    "    print(\"Using loaded model, updating environment...\")\n",
    "    model.set_env(env)\n",
    "    print(\"✓ Model updated\")\n",
    "\n",
    "# Print GPU memory usage\n",
    "if device == 'cuda':\n",
    "    allocated = torch.cuda.memory_allocated(0) / 1e9\n",
    "    reserved = torch.cuda.memory_reserved(0) / 1e9\n",
    "    print(f\"\\nGPU Memory: Allocated={allocated:.2f}GB, Reserved={reserved:.2f}GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Setup Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import CheckpointCallback, CallbackList\n",
    "from training_callback import DetailedLoggingCallback\n",
    "\n",
    "# Checkpoint callback - save every 50K steps\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq=50_000 // CONFIG['n_envs'],\n",
    "    save_path=os.path.join(CONFIG['output_dir'], 'checkpoints'),\n",
    "    name_prefix='phase5_model'\n",
    ")\n",
    "\n",
    "# Detailed logging\n",
    "logging_callback = DetailedLoggingCallback(verbose=1)\n",
    "\n",
    "callbacks = CallbackList([checkpoint_callback, logging_callback])\n",
    "\n",
    "print(\"✓ Callbacks configured\")\n",
    "print(f\"  Checkpoint frequency: {50_000 // CONFIG['n_envs']} steps per env\")\n",
    "print(f\"  Checkpoint directory: {os.path.join(CONFIG['output_dir'], 'checkpoints')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Start Training\n",
    "\n",
    "This cell will start the training process. It may take several hours depending on:\n",
    "- Your GPU performance\n",
    "- Number of timesteps\n",
    "- Number of parallel environments\n",
    "\n",
    "**Note:** You can interrupt training at any time (Kernel → Interrupt). The latest checkpoint will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Device: {device.upper()}\")\n",
    "print(f\"Map: {CONFIG['map_name']}\")\n",
    "print(f\"Opponents: {CONFIG['num_bots']} bots\")\n",
    "print(f\"Self-Play: {CONFIG['use_self_play']}\")\n",
    "print(f\"Total Timesteps: {CONFIG['total_timesteps']:,}\")\n",
    "print(f\"Parallel Environments: {CONFIG['n_envs']}\")\n",
    "print(f\"Output: {CONFIG['output_dir']}\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nPress Kernel → Interrupt to stop training early.\\n\")\n",
    "\n",
    "try:\n",
    "    model.learn(\n",
    "        total_timesteps=CONFIG['total_timesteps'],\n",
    "        callback=callbacks,\n",
    "        progress_bar=True,\n",
    "        tb_log_name='phase5_training'\n",
    "    )\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"✓ TRAINING COMPLETE!\")\n",
    "    print(\"=\" * 70)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"⚠️  Training interrupted by user\")\n",
    "    print(\"=\" * 70)\n",
    "finally:\n",
    "    # Show final GPU memory\n",
    "    if device == 'cuda':\n",
    "        allocated = torch.cuda.memory_allocated(0) / 1e9\n",
    "        reserved = torch.cuda.memory_reserved(0) / 1e9\n",
    "        print(f\"\\nFinal GPU Memory: Allocated={allocated:.2f}GB, Reserved={reserved:.2f}GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_path = os.path.join(CONFIG['output_dir'], 'phase5_final')\n",
    "model.save(final_path)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"✓ Model saved to: {final_path}\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nCheckpoints available at:\")\n",
    "print(f\"  {os.path.join(CONFIG['output_dir'], 'checkpoints')}\")\n",
    "print(f\"\\nTensorBoard logs available at:\")\n",
    "print(f\"  {os.path.join(CONFIG['output_dir'], 'logs')}\")\n",
    "print(f\"\\nTo view logs, run:\")\n",
    "print(f\"  tensorboard --logdir {os.path.join(CONFIG['output_dir'], 'logs')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close environments\n",
    "env.close()\n",
    "print(\"✓ Environments closed\")\n",
    "\n",
    "# Clear GPU cache if using CUDA\n",
    "if device == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"✓ CUDA cache cleared\")\n",
    "\n",
    "print(\"\\n✓ All done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Monitor Training (Optional)\n",
    "\n",
    "Run this cell in a separate terminal to monitor training progress:\n",
    "\n",
    "```bash\n",
    "# Start TensorBoard\n",
    "tensorboard --logdir phase5-implementation/runs\n",
    "\n",
    "# Then open: http://localhost:6006\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for JupyterHub\n",
    "\n",
    "1. **Keep Session Alive**: Make sure your JupyterHub session doesn't timeout during long training runs\n",
    "2. **Monitor GPU Usage**: Use `nvidia-smi` in a terminal to monitor GPU usage\n",
    "3. **Save Checkpoints**: Training automatically saves checkpoints every 50K steps\n",
    "4. **Adjust Batch Size**: If you get OOM errors, reduce `batch_size` and `n_steps` in CONFIG\n",
    "5. **Use TensorBoard**: Monitor training metrics in real-time with TensorBoard\n",
    "\n",
    "### Recommended GPU Settings:\n",
    "\n",
    "| GPU Memory | n_envs | batch_size | n_steps |\n",
    "|------------|--------|------------|----------|\n",
    "| 8 GB       | 8      | 256        | 1024    |\n",
    "| 16 GB      | 16     | 512        | 2048    |\n",
    "| 24 GB+     | 24     | 1024       | 4096    |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
